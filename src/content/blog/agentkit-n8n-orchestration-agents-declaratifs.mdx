---
title: "AgentKit : du flux n8n √† l'orchestration d'agents d√©claratifs"
pubDate: "2025-10-27"
slug: "agentkit-n8n-orchestration-agents-declaratifs"
draft: false
categories:
  - "Tutoriels"
tags:
  - "automatisation"
  - "IA"
  - "performances"
description: "De l‚Äôautomatisation visuelle (n8n) √† la conception d‚Äôagents d√©claratifs : d√©couverte d‚ÄôAgentKit, la nouvelle approche d‚ÄôOpenAI pour orchestrer des intelligences robustes, tra√ßables et interop√©rables via YAML et API ouvertes."
image: /image/473798286-8bc39384-1687-47bc-988d-8bfa090aa57e.avif
---

import { Code } from 'astro-expressive-code/components';


_AgentKit : du flux n8n √† l‚Äôorchestration d‚Äôagents d√©claratifs ‚Äì Vers une IA plus robuste et portable_

## Une mutation silencieuse



Depuis quelques ann√©es, la construction de pipelines d'automatisation s'appuie sur des outils visuels comme **n8n**, **Make** ou **Zapier**. Ces plateformes ont simplifi√© - pour ne pas dire r√©volutionn√© - l'orchestration de flux m√©tier : un √©v√©nement d√©clenche une s√©rie d'actions, qui font circuler la donn√©e d'un service √† un autre. Cette logique a √©volu√© avec l'arriv√©e des mod√®les de langage (LLM) : les flux ne se contentent plus d'ex√©cuter, ils interpr√®tent.



Mais cette puissance nouvelle s'est accompagn√©e d'une difficult√© croissante : **g√©rer la complexit√© de l'intelligence** elle-m√™me. Dans n8n, par exemple, tu peux cha√Æner des appels √† OpenAI, v√©rifier la structure JSON, relancer des requ√™tes si la sortie est mal form√©e, etc. √áa fonctionne, mais √† mesure que le flux s'enrichit, il devient lourd, peu lisible et difficile √† maintenir.



C'est dans ce contexte qu'OpenAI a annonc√©, lors du **DevDay du 6 octobre 2025** (San Francisco), [le lancement d'**AgentKit**](https://openai.com/index/introducing-agentkit/), un environnement destin√© √† simplifier la conception et l'orchestration d'agents autonomes. Le projet est actuellement en **b√™ta ouverte** pour certains d√©veloppeurs. Il n'est pas open source mais repose sur des standards ouverts (YAML, JSON, API REST). Certaines briques, comme la **Connector Registry**, restent encore en d√©ploiement progressif.



AgentKit ne se veut pas un nouvel outil d'automatisation, mais plut√¥t une **plateforme de conception d'agents intelligents**. En d'autres termes : une tentative d'industrialiser ce qu'on faisait jusque-l√† √† la main.



## De n8n √† l'agent autonome : repenser la cha√Æne de traitement



Prenons un cas concret. Depuis quelques mois, j'utilise **n8n** [pour automatiser ma veille hebdomadaire](/blog/pocket-migration-wallabag/) sur les technologies open source :



* R√©cup√©ration d'articles via **Wallabag**.
* Nettoyage HTML ‚Üí Markdown.
* Analyse IA (r√©sum√©, scoring, mots-cl√©s, cat√©gorisation).
* Insertion en base PostgreSQL.
* G√©n√©ration HTML pour la newsletter.
* Diffusion automatique.



Un flux efficace, mais o√π chaque bloc IA demande une vigilance particuli√®re : un **JSON mal form√©**, une **valeur absente**, ou une **cat√©gorie incoh√©rente** peuvent bloquer la cha√Æne. Il faut multiplier les n≈ìuds de v√©rification et les boucles de secours. En somme : une orchestration fonctionnelle mais fragile.



C'est pr√©cis√©ment ce maillon qu'AgentKit cherche √† renforcer : non pas la collecte ou la diffusion, mais **la couche cognitive** du flux. L√† o√π n8n orchestre des appels, AgentKit **d√©crit des intentions**.



## AgentKit : une logique d√©clarative



AgentKit repose sur un principe simple : d√©crire un agent dans un format d√©claratif. Tu ne programmes plus son comportement pas √† pas, tu le **d√©finis** dans un fichier YAML. Celui-ci contient :



* Les **entr√©es** (inputs).
* Le **mod√®le** utilis√© (OpenAI, OpenRouter, Mistral, Gemini...).
* Le **prompt** principal.
* Les **contraintes de sortie** (sch√©ma JSON attendu).
* Les **outils** ou fonctions accessibles √† l'agent.



Cette structure rend l'agent **portable** et lisible : le m√™me fichier YAML peut √™tre ex√©cut√© localement ou d√©ploy√© demain dans l'environnement natif AgentKit. Et si AgentKit venait √† √©voluer radicalement ou √† dispara√Ætre ? Pas de panique : le format YAML et ton runner local restent fonctionnels. C'est tout l'enjeu d'un standard ouvert et durable.



## Exemple : la portion de flux n8n remplac√©e



Dans le flux n8n d'origine, le c≈ìur du traitement IA ressemblait √† ceci :



```
[HTTP Request ‚Üí OpenAI API]
‚Üí R√©sum√© + mots-cl√©s + score JSON
‚Üí V√©rification JSON
‚Üí Enregistrement SQL
```



Un sch√©ma simple mais vuln√©rable √† la moindre erreur de format. Avec AgentKit, cette partie devient un agent √† part enti√®re, d√©crit ainsi :

<Code code={`agent:
name: resume\_keywords\_agent
description: >
Analyse un contenu web pour g√©n√©rer un r√©sum√© orient√© business,
avec notation et classification normalis√©e.
inputs:
- markdown\_content: string
model:
provider: variable
model\_name: variable
temperature: 0.1
response\_format: json
prompt: |
Tu es un analyste technologique sp√©cialis√© dans les solutions open-source et automatisables.
Analyse le contenu suivant et produis une √©valuation orient√©e business pratique, en fran√ßais.
Crit√®res :
- Applicabilit√© PME/freelances (0 √† 3)
- Potentiel d'automatisation (0 √† 2)
- Aspect √©conomique concret (0 √† 2)
- Open-source / self-hosted (0 √† 2)
- Innovation vs √©tabli (0 √† 1)
Format attendu :
{
"applicabilite\_pme": 0,
"potentiel\_automatisation": 0,
"aspect\_economique": 0,
"open\_source": 0,
"innovation": 0,
"score\_global": 0,
"summary": "...",
"keywords": ["..."],
"category": "..."
}
Contenu : {{markdown\_content}}
`} lang="yaml" />

Ce fichier, versionn√© et auditable, remplace plusieurs n≈ìuds dans n8n.



## Le runner universel : un interpr√©teur maison



AgentKit n'√©tant pas encore totalement disponible, j'ai d√©velopp√© un **runner Python** pour ex√©cuter ces fichiers YAML localement. Ce script :



* lit le YAML,
* remplace les variables dans le prompt,
* envoie la requ√™te au mod√®le LLM (OpenRouter, Mistral, DeepInfra...),
* valide la sortie via **Pydantic**,
* relance automatiquement en cas de JSON invalide.



Voici un extrait du mod√®le de validation :

<Code code={`from pydantic import BaseModel, conint, Field
from typing import List
class ResumeKeywordsOutput(BaseModel):
applicabilite\_pme: conint(ge=0, le=3)
potentiel\_automatisation: conint(ge=0, le=2)
aspect\_economique: conint(ge=0, le=2)
open\_source: conint(ge=0, le=2)
innovation: conint(ge=0, le=1)
score\_global: conint(ge=0, le=10)
summary: str
keywords: List[str] = Field(..., min\_items=3)
category: str
`} lang="python" />

Et la boucle principale :

<Code code={`def run\_agent(agent\_config, variables, max\_retries=2):
template = Template(agent\_config["agent"]["prompt"])
rendered = template.render(\*\*variables)
for attempt in range(1, max\_retries + 1):
try:
raw = call\_llm(rendered)
parsed = json.loads(raw)
validated = ResumeKeywordsOutput(\*\*parsed)
return {"success": True, "output": validated.dict(), "attempt": attempt}
except json.JSONDecodeError:
print(f"JSON invalide (tentative {attempt}) ‚Üí relance")
rendered = f"Corrige ce JSON invalide et renvoie uniquement le JSON corrig√© :\n{raw}"
except Exception as e:
if attempt == max\_retries:
return {"success": False, "error": str(e)}
`} lang="python" />

**üì¶ Note sur la composition**



En production, avec des dizaines d'agents et des prompts de plusieurs milliers de tokens, un YAML monolithique devient rapidement ing√©rable. L'approche recommand√©e consiste √† **d√©couper en composants r√©utilisables** :



* **Prompts modulaires** : extraire les instructions communes (`prompts/base/analyst_role.md`, `prompts/base/output_format.md`)
* **Sch√©mas partag√©s** : centraliser les formats JSON de sortie (`schemas/scoring.json`)
* **Composition par r√©f√©rence** : utiliser des includes dans le YAML ou des variables d'environnement



Exemple de structure compos√©e :

<Code code={`agent:
name: resume\_keywords\_agent
prompt\_parts:
- role: "{{include('prompts/base/analyst\_role.md')}}"
- criteria: "{{include('prompts/scoring/criteria\_v2.md')}}"
- input: "Contenu : {{markdown\_content}}"
output\_schema: "{{load('schemas/scoring.json')}}"
`} lang="yaml" />

Le runner peut alors r√©soudre ces r√©f√©rences avant ex√©cution, ce qui permet de versionner chaque brique ind√©pendamment et de propager rapidement les mises √† jour communes √† tous tes agents.



Une fois ce runner op√©rationnel, **l'exposer via FastAPI devient trivial**.



### API FastAPI : rendre l'agent accessible



Avec FastAPI, l'agent devient un service REST local. n8n, un front Vue3 ou tout autre syst√®me peut le consommer sans se soucier de la logique interne :

<Code code={`@app.post("/analyze")
def analyze(req: AgentRequest):
agent\_config = load\_agent(f"agents/{req.agent\_name}.yaml")
result = run\_agent(agent\_config, {"markdown\_content": req.markdown\_content})
return result
`} lang="python" />

Un simple `POST /analyze` retourne une r√©ponse propre, valid√©e et exploitable :

<Code code={`{
"success": true,
"output": {
"applicabilite\_pme": 3,
"potentiel\_automatisation": 2,
"aspect\_economique": 2,
"open\_source": 2,
"innovation": 1,
"score\_global": 9,
"summary": "Nouvelle √©volution de Milvus, simplifiant la gestion vectorielle locale...",
"keywords": ["Milvus", "vector store", "LLM", "self-hosted"],
"category": "IA & stockage vectoriel"
},
"attempt": 1
}
`} lang="json" />

## Ce que √ßa change



### Lisibilit√© et portabilit√©



Le YAML devient un contrat clair entre d√©veloppeur et agent : versionnable, diffable, document√©.



### Robustesse et validation



Pydantic garantit que les donn√©es retourn√©es sont coh√©rentes avant toute utilisation.



### D√©couplage fort



L'agent peut √™tre ex√©cut√© depuis n8n, FastAPI ou un orchestrateur tiers, sans d√©pendance technique.



### Tra√ßabilit√© et audit



Chaque ex√©cution peut √™tre journalis√©e : mod√®le utilis√©, tentative, dur√©e, sortie. √áa ouvre la voie √† une **observabilit√© IA** digne de ce nom.



### Une approche durable



AgentKit ne remplace pas les orchestrateurs : il les compl√®te. On passe d'un encha√Ænement de fonctions √† un **design d'agents autonomes**.



## Limites et perspectives



AgentKit reste en phase de g√©n√©ralisation progressive. Les connecteurs API, la s√©curit√© (rate limiting, validation des entr√©es, sandboxing) et le monitoring sont encore en cours d'int√©gration. L'ex√©cution d'agents YAML n√©cessite √©galement une attention particuli√®re aux vecteurs d'injection : validation stricte des variables, sandboxing des appels externes, et signature des fichiers agents en environnement sensible.



Les co√ªts li√©s aux retri, notamment sur des API √† facturation par token, peuvent aussi peser dans des contextes √† grand volume : **un agent qui relance 2 fois sur 30% des requ√™tes augmente la facture API de 60%**. Un prompt engineering soign√© et des strat√©gies de backoff peuvent att√©nuer cet impact.



Mais l'approche est d√©j√† **r√©plicable localement**. En d'autres termes : tu peux tester le concept d√®s maintenant, sans attendre l'infrastructure compl√®te d'OpenAI. L'id√©e n'est pas de remplacer les frameworks existants (LangChain, CrewAI, etc.), mais de proposer un **format pivot**, plus universel, o√π les agents deviennent des entit√©s d√©clar√©es, r√©utilisables et √©valuables.


Contrairement √† LangChain, qui impose une stack Python, AgentKit mise sur un format YAML universel, compatible avec n‚Äôimporte quel langage.


## Conclusion



L'arriv√©e d'AgentKit marque une √©tape vers une IA plus structur√©e et plus pr√©visible. L'enjeu n'est plus d'appeler un mod√®le, mais de **concevoir des agents robustes**, tra√ßables et interop√©rables.



L'orchestration ne sera plus un assemblage de blocs, mais une **composition d'intentions**.


> En somme, ce que YAML a fait pour l'infrastructure, AgentKit s'appr√™te √† le faire pour les intelligences.



C'est encore jeune, mais la direction est claire : **moins de flux √† maintenir, plus d‚Äôagents autonomes et r√©utilisables : AgentKit pourrait bien devenir le standard pour une IA industrialis√©e.**
